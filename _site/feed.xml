<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/my2cents/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/my2cents/" rel="alternate" type="text/html" /><updated>2021-04-25T21:55:20-07:00</updated><id>http://localhost:4000/my2cents/feed.xml</id><title type="html">Blog - Thai Duong</title><entry><title type="html">Physics-guided dynamics learning (Part 3)</title><link href="http://localhost:4000/my2cents/PhysicsGuidedLearning3/" rel="alternate" type="text/html" title="Physics-guided dynamics learning (Part 3)" /><published>2021-04-24T00:00:00-07:00</published><updated>2021-04-24T00:00:00-07:00</updated><id>http://localhost:4000/my2cents/PhysicsGuidedLearning3</id><content type="html" xml:base="http://localhost:4000/my2cents/PhysicsGuidedLearning3/">&lt;p&gt;&lt;em&gt;Apr. 24, 2021&lt;/em&gt;. In &lt;a href=&quot;https://thaipduong.github.io/my2cents/PhysicsGuidedLearning2/&quot;&gt;part 2&lt;/a&gt;, we talked about model design for dynamics learning based on Lagrangian dynamics. Today, I’ll summarize another interesting paper in this direction that combines Hamiltonian dynamics with &lt;a href=&quot;https://thaipduong.github.io/my2cents/NeuralODE/&quot;&gt;neural ODE networks&lt;/a&gt; to learn robot dynamics: &lt;a href=&quot;https://arxiv.org/abs/1909.12077&quot;&gt;“Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control”&lt;/a&gt; by Zhong et al.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;hamiltonian-dynamics&quot;&gt;Hamiltonian Dynamics&lt;/h2&gt;
&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\dot{q}&lt;/script&gt; be the generalized coordinates and the generalized velocity, respectively. As seen in in &lt;a href=&quot;https://thaipduong.github.io/my2cents/PhysicsGuidedLearning2/&quot;&gt;the previous post on Lagrangian dynamics&lt;/a&gt;, the Lagrangian is the difference between the kinetic energy and the potential energy:
\[ L(q, \dot{q}) = \frac{1}{2}\dot{q}^\top M(q) \dot{q} - V(q), \]
where &lt;script type=&quot;math/tex&quot;&gt;M(q)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;V(q)&lt;/script&gt; are the generalized mass and potential energy of the system, respectively. Instead of using the velocity &lt;script type=&quot;math/tex&quot;&gt;\dot{q}&lt;/script&gt;, Hamiltonian dynamics uses generalized momenta &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;, defined as:
\[ p = \frac{\partial L(q,\dot{q}}{\partial \dot{q}} = M(q)\dot{q} \quad \text{(Legendre transform)}. \]
Now, we define a Hamiltonian function &lt;script type=&quot;math/tex&quot;&gt;H(q,p)&lt;/script&gt; as the total energy of the system:
\[ H(q,p) = \frac{1}{2}p^\top M^{-1}(q)p + V(q). \]
The dynamics of the system is governed by Hamilton’s equations:
\[ \dot{q} = \frac{\partial H}{\partial p}, \dot{p} = -\frac{\partial H}{\partial q} + g(q) u \quad \text{(Hamilton’s equations)},\]
where &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; is a generalized control input, i.e. external forces. Note that if &lt;script type=&quot;math/tex&quot;&gt;u = 0&lt;/script&gt;, we have &lt;script type=&quot;math/tex&quot;&gt;\frac{d}{dt}H(q,p) = 0&lt;/script&gt;, i.e. the total energy is conserved.&lt;/p&gt;

&lt;h2 id=&quot;learning-hamiltonian-dynamics&quot;&gt;Learning Hamiltonian Dynamics&lt;/h2&gt;
&lt;p&gt;Knowing the (symplectic) form of Hamilton’s equations, &lt;a href=&quot;https://arxiv.org/abs/1909.12077&quot;&gt;Zhong et al.&lt;/a&gt; design the structure of a &lt;a href=&quot;https://thaipduong.github.io/my2cents/NeuralODE/&quot;&gt;neural ODE network&lt;/a&gt; to impose the contraints of energy conservation. Let &lt;script type=&quot;math/tex&quot;&gt;x = [q^\top, p^\top]^\top&lt;/script&gt;, the dynamics described by the Hamilton’s equations above is approximated by a function &lt;script type=&quot;math/tex&quot;&gt;\hat{f}_\theta&lt;/script&gt; as follows:
\[ \begin{bmatrix} \dot{x} \\ \dot{u} \end{bmatrix} = \begin{bmatrix} \hat{f}_\theta(x,u) \\ 0 \end{bmatrix}. \]&lt;/p&gt;
&lt;h3 id=&quot;network-structure&quot;&gt;Network Structure&lt;/h3&gt;

&lt;p&gt;To respect the Hamiltonian dynamics, three neural networks &lt;script type=&quot;math/tex&quot;&gt;\hat{M}^{-1}_{\theta_1}(q), \hat{V}_{\theta_2}(q)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{g}_{\theta_3}(q)&lt;/script&gt; are used to approximate the generalized mass inverse, the potential energy, and the input matrix. The approximated Hamiltonian is then calulated as:&lt;/p&gt;

&lt;p&gt;\[ \hat{H}_{\theta_1, \theta_2}(q,p) = \frac{1}{2} p^\top \hat{M}^{-1}(q) p + \hat{V}(q) \]&lt;/p&gt;

&lt;p&gt;Based on the approximated Hamiltonian, the approximated dynamics &lt;script type=&quot;math/tex&quot;&gt;\hat{f}_\theta&lt;/script&gt; has the following form:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{f}_\theta(x,u) = \begin{bmatrix} \frac{\partial \hat{H}}{\partial p} \\\\ -\frac{\partial \hat{H}}{\partial q} \end{bmatrix} + \begin{bmatrix} 0 \\\\ g_{\theta_3}(q) \end{bmatrix}u,&lt;/script&gt;

&lt;p&gt;where the partial derivatives are computed via autodifferentiation.&lt;/p&gt;
&lt;h3 id=&quot;data-generation-and-training&quot;&gt;Data Generation and Training&lt;/h3&gt;
&lt;p&gt;Given the paramterized function &lt;script type=&quot;math/tex&quot;&gt;\hat{f}_\theta(x,u)&lt;/script&gt;, the neural ODE framework is used for training and testing. However, this form of &lt;script type=&quot;math/tex&quot;&gt;\hat{f}_\theta(x,u)&lt;/script&gt; requires the generalized momenta &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; in the dataset, which is not often available. If we have &lt;script type=&quot;math/tex&quot;&gt;(q,\dot{q})&lt;/script&gt; in the dataset instead, the dynamics of &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; in the Hamilton’s equations can be replaced by the dynamics of &lt;script type=&quot;math/tex&quot;&gt;\dot{q}&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ddot{q} = \frac{d}{dt} \dot{q} = \frac{d}{dt} \hat{M}^{-1}(q)p = \frac{d}{dt}(\hat{M}^{-1}(q))p + \hat{M}^{-1}(q) \dot{p},&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;p = \hat{M}(q)q&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;\dot{p} = -\frac{\partial H}{\partial q} + g(q) u.&lt;/script&gt; Now, training can be done for the dynamics of &lt;script type=&quot;math/tex&quot;&gt;(q,\dot{q})&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;energy-based-control&quot;&gt;Energy-based Control&lt;/h2&gt;
&lt;p&gt;Since the Hamiltonian is the total energy of the system, energy-based control is a natural choice for driving the system to a desired state. The paper only considers fully actuated systems and uses energy-shaping and damping injection (ES-DI) approach to shape the potential energy. For under-actuated systems, both kinetic and potential energy need to be shaped. However, the paper does not consider this case.&lt;/p&gt;

&lt;h2 id=&quot;comments&quot;&gt;Comments&lt;/h2&gt;
&lt;p&gt;How does it work with a robot with complicated dynamics? The experiments in the paper are carried out only on simple platform such as pendulums, cartpoles, etc.&lt;/p&gt;</content><author><name></name></author><summary type="html">Apr. 24, 2021. In part 2, we talked about model design for dynamics learning based on Lagrangian dynamics. Today, I’ll summarize another interesting paper in this direction that combines Hamiltonian dynamics with neural ODE networks to learn robot dynamics: “Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control” by Zhong et al.</summary></entry><entry><title type="html">Physics-guided dynamics learning (Part 2)</title><link href="http://localhost:4000/my2cents/PhysicsGuidedLearning2/" rel="alternate" type="text/html" title="Physics-guided dynamics learning (Part 2)" /><published>2021-04-21T00:00:00-07:00</published><updated>2021-04-21T00:00:00-07:00</updated><id>http://localhost:4000/my2cents/PhysicsGuidedLearning2</id><content type="html" xml:base="http://localhost:4000/my2cents/PhysicsGuidedLearning2/">&lt;p&gt;&lt;em&gt;Apr. 21, 2021&lt;/em&gt;. There are three main formulations for the dynamics of a physical system: &lt;a href=&quot;https://en.wikipedia.org/wiki/Newtonian_dynamics&quot;&gt;Newton dynamics&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrangian_mechanics&quot;&gt;Lagrangian dynamics&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamiltonian_mechanics&quot;&gt;Hamiltonian dynamics&lt;/a&gt;. Today, let’s take a look at a couple of papers on Deep Lagrangian Networks (&lt;a href=&quot;https://arxiv.org/abs/1907.04490&quot;&gt;pdf1&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1907.04489&quot;&gt;pdf2&lt;/a&gt;) by &lt;a href=&quot;http://www.mlutter.eu/&quot;&gt;Lutter&lt;/a&gt; et al. that incorporate Lagrangian dynamics into a machine learning model. The main idea of Deep Lagrangian Network (DeLaN) is to use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Euler%E2%80%93Lagrange_equation&quot;&gt;Euler-Langrage equation&lt;/a&gt; to design the network structure that respects &lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrangian_mechanics&quot;&gt;Lagrangian Dynamics&lt;/a&gt;.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;common-formulations-of-classical-mechanics&quot;&gt;Common formulations of classical mechanics&lt;/h2&gt;
&lt;p&gt;There are three main formulations: &lt;a href=&quot;https://en.wikipedia.org/wiki/Newtonian_dynamics&quot;&gt;Newton dynamics&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrangian_mechanics&quot;&gt;Lagrangian dynamics&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Hamiltonian_mechanics&quot;&gt;Hamiltonian dynamics&lt;/a&gt;. While Newton dynamics uses Cartersian coordinates and forces to express the motion of an object, Lagrangian and Hamiltonian dynamics use the notion of energy with generalized coordinates &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;. Lagrangian describes the motion in the configuration space, i.e. the product space of &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\dot{q}&lt;/script&gt;. Meanwhile, Hamiltonian does it in the phase space, i.e. the product space of &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; and generalized momenta &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;lagrangian-dynamics&quot;&gt;Lagrangian Dynamics&lt;/h2&gt;
&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; be the generalized state of a dynamical system and &lt;script type=&quot;math/tex&quot;&gt;\tau&lt;/script&gt; be the control input. In general, the system dynamics has the following form:&lt;/p&gt;

&lt;p&gt;\[f(q, \dot{q}, \tau) = \ddot{q} \quad\text{(forward model)},\]
or 
\[f^{-1}(q, \dot{q}, \ddot{q}) = \tau \quad\text{(inverse model)}.\]&lt;/p&gt;

&lt;p&gt;In Lagrangian mechanics, the Lagrangian &lt;script type=&quot;math/tex&quot;&gt;L(q,\dot{q})&lt;/script&gt; is defined as the difference of the kinetic energy &lt;script type=&quot;math/tex&quot;&gt;T(q,\dot{q}) = \frac{1}{2}\dot{q}^\top H(q) \dot{q}&lt;/script&gt; and the potential energy &lt;script type=&quot;math/tex&quot;&gt;V(q)&lt;/script&gt;:&lt;/p&gt;

&lt;p&gt;\[L(q,\dot{q}) = T(q,\dot{q}) - V(q) =  \frac{1}{2}\dot{q}^\top H(q) \dot{q} - V(q).\]&lt;/p&gt;

&lt;p&gt;The Lagrangian &lt;script type=&quot;math/tex&quot;&gt;L(q,\dot{q})&lt;/script&gt; satisfies the Euler-Lagrangian equation:&lt;/p&gt;

&lt;p&gt;\[ \frac{d}{dt} \frac{\partial L}{\partial \dot{q}_i} - \frac{\partial L}{\partial q_i} = \tau_i, \]
or 
\[ H(q)\ddot{q} + \dot{H}(q)\dot{q} - \frac{1}{2}\left( \frac{\partial}{\partial q} \left( \dot{q}^\top H(q)\dot{q} \right) \right)^\top + g(q) = \tau, \]
where &lt;script type=&quot;math/tex&quot;&gt;g(q) = \frac{dV}{dq}&lt;/script&gt;. Note that this is the inverse model &lt;script type=&quot;math/tex&quot;&gt;f^{-1}&lt;/script&gt; mentioned above.&lt;/p&gt;

&lt;h2 id=&quot;network-architecture&quot;&gt;Network Architecture&lt;/h2&gt;
&lt;p&gt;To approximate the (inverse) dynamics &lt;script type=&quot;math/tex&quot;&gt;f^{-1}&lt;/script&gt;, DeLaN approximates &lt;script type=&quot;math/tex&quot;&gt;H(q)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;g(q)&lt;/script&gt; by neural networks &lt;script type=&quot;math/tex&quot;&gt;\hat{H}(q)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{g}(q)&lt;/script&gt; with paramters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;, respectively. The output of the network &lt;script type=&quot;math/tex&quot;&gt;\hat{H}(q)&lt;/script&gt; is a positive definite matrix and can be described as:
\[ \hat{H}(q) = \hat{D}(q)\hat{D}(q)^\top.\]
Both &lt;script type=&quot;math/tex&quot;&gt;\hat{H}(q)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{g}(q)&lt;/script&gt; are represented by two feed-forward neural networks. The approximated inverse dynamics &lt;script type=&quot;math/tex&quot;&gt;\hat{f}^{-1}&lt;/script&gt; is:
\[ \hat{f}^{-1}(q,\dot{q}, \ddot{q}) =  \hat{H}(q)\ddot{q} + \dot{\hat{H}}(q)\dot{q} - \frac{1}{2}\left( \frac{\partial}{\partial q} \left( \dot{q}^\top \hat{H}(q)\dot{q} \right) \right)^\top + \hat{g}(q) = \tau, \]&lt;/p&gt;

&lt;p&gt;The forward dynamics is:
\[ \hat{f}(q,\dot{q}, \ddot{q}) =  \hat{H}^{-1}(q)\left(\tau - \dot{\hat{H}}(q)\dot{q} + \frac{1}{2}\left( \frac{\partial}{\partial q} \left( \dot{q}^\top \hat{H}(q)\dot{q} \right) \right)^\top - \hat{g}(q) \right) = \ddot{q}, \]&lt;/p&gt;

&lt;h2 id=&quot;dynamics-learning&quot;&gt;Dynamics Learning&lt;/h2&gt;
&lt;p&gt;Data points of the form &lt;script type=&quot;math/tex&quot;&gt;(q_n, \dot{q}_n, \ddot{q}_n, \tau_n)_{n=1}^n&lt;/script&gt; are collected from robot trajectories. The parameters of the neural networks &lt;script type=&quot;math/tex&quot;&gt;\hat{H}(q)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{g}(q)&lt;/script&gt; are trained to minimize the loss function:
\[ \mathcal{L} = \frac{1}{N}\sum_{n=1}^N l(\hat{f}^{-1}(q_n,\dot{q}_n, \ddot{q}_n), \tau_n) + \lambda \Omega(\theta),\]
where &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is some loss function defining the distance between the actual control input and the approximate one. As any affine transformation of a Lagrangian is also an Lagragian, &lt;script type=&quot;math/tex&quot;&gt;\Omega(\theta)&lt;/script&gt;, a quantity measuring how large the the parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; are, is added to the loss function for parameter regulation.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;https://arxiv.org/abs/1907.04489&quot;&gt;extended version of DeLaN&lt;/a&gt;, both forward and inverse dynamics are used in the loss function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L} = \frac{1}{N}\sum_{n=1}^N l_1(\hat{f}(q_n,\dot{q}_n, \tau_n), \ddot{q}_n) + \frac{1}{N}\sum_{n=1}^N l_2(\hat{f}^{-1}(q_n,\dot{q}_n, \ddot{q}_n), \tau_n) + \lambda \Omega(\theta)&lt;/script&gt;

&lt;h2 id=&quot;external-forces&quot;&gt;External Forces&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&quot;https://arxiv.org/abs/1907.04489&quot;&gt;extended version of DeLaN&lt;/a&gt; models external forces like friction as a term in the total control input &lt;script type=&quot;math/tex&quot;&gt;\tau = \sum_{i} \tau_i&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;control&quot;&gt;Control&lt;/h2&gt;
&lt;p&gt;The original paper uses feed-forward controller for trajectory tracking. The extended version uses an energy-based controller proposed in the paper &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1474667017581057&quot;&gt;“Energy based control of a class of underactuated mechanical systems”&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;comments&quot;&gt;Comments&lt;/h2&gt;
&lt;p&gt;How does this method work with robots with more complicated dynamics? Pendulums seem to be simple.&lt;/p&gt;</content><author><name></name></author><summary type="html">Apr. 21, 2021. There are three main formulations for the dynamics of a physical system: Newton dynamics, Lagrangian dynamics and Hamiltonian dynamics. Today, let’s take a look at a couple of papers on Deep Lagrangian Networks (pdf1, pdf2) by Lutter et al. that incorporate Lagrangian dynamics into a machine learning model. The main idea of Deep Lagrangian Network (DeLaN) is to use the Euler-Langrage equation to design the network structure that respects Lagrangian Dynamics.</summary></entry><entry><title type="html">Physics-guided dynamics learning (Part 1)</title><link href="http://localhost:4000/my2cents/PhysicsGuidedLearning/" rel="alternate" type="text/html" title="Physics-guided dynamics learning (Part 1)" /><published>2021-04-08T00:00:00-07:00</published><updated>2021-04-08T00:00:00-07:00</updated><id>http://localhost:4000/my2cents/PhysicsGuidedLearning</id><content type="html" xml:base="http://localhost:4000/my2cents/PhysicsGuidedLearning/">&lt;p&gt;&lt;em&gt;Apr. 08, 2021&lt;/em&gt;. Recently, I am very interested in integrating prior physics knowledge into learning dynamics of a robot. In many applications, the dynamics of a robot has to satisfy physics-based constraints such as energy conservation and state manifolds such as SO(3) and SE(3). However, expressive models such as neural networks generally do not enforce these constraints and might struggle to generalize them from the data. Interestingly, prior knowledge about the dynamical systems can be used to design the learning model so that the constraints are automatically satisfied. A few examples of the prior knowledge are kinematic constraints, PDE symmetry, Lagrangian dynamics, and Hamiltonian dynamics. Below are a few interesting papers in this category.
&lt;!--more--&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Kinematic constraints:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1806.01242&quot;&gt;Graph networks as learnable physics engines for inference and control&lt;/a&gt; by Sanchez-Gonzalez et al.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;PDE symmetry:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.04272&quot;&gt;Deep Neural Networks Motivated by Partial Differential Equations&lt;/a&gt; by Ruthotto and Haber.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.03061&quot;&gt;Incorporating Symmetry into Deep Dynamics Models for Improved Generalization&lt;/a&gt; by Wang et al.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Lagrangian mechanics:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2003.04630&quot;&gt;Lagrangian Neural Networks&lt;/a&gt; by Cranmer et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1902.08705&quot;&gt;A General Framework for Structured Learning of Mechanical Systems&lt;/a&gt; by Gupta et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.04489&quot;&gt;Deep Lagrangian Networks for end-to-end learning of energy-based control for under-actuated systems&lt;/a&gt; by Lutter et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.04490&quot;&gt;Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning&lt;/a&gt; by Lutter et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2005.14617&quot;&gt;Modeling System Dynamics with Physics-Informed Neural Networks Based on Lagrangian Mechanics&lt;/a&gt; by Roehrl et al.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hamiltonian dynamics:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.12715&quot;&gt;On Learning Hamiltonian Systems from Data&lt;/a&gt; by Bertalan et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1909.13334&quot;&gt;Symplectic Recurrent Neural Networks&lt;/a&gt; by Chen et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/2010.13581&quot;&gt;Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit Constraints&lt;/a&gt; by Finzi et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1906.01563&quot;&gt;Hamiltonian Neural Networks&lt;/a&gt; by Greydanus et al.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1909.12077&quot;&gt;Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control&lt;/a&gt; by Zhong et al.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Survey: &lt;a href=&quot;https://arxiv.org/abs/2003.04919&quot;&gt;Integrating Physics-Based Modeling with Machine Learning: A Survey&lt;/a&gt; by Willard et al.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Apr. 08, 2021. Recently, I am very interested in integrating prior physics knowledge into learning dynamics of a robot. In many applications, the dynamics of a robot has to satisfy physics-based constraints such as energy conservation and state manifolds such as SO(3) and SE(3). However, expressive models such as neural networks generally do not enforce these constraints and might struggle to generalize them from the data. Interestingly, prior knowledge about the dynamical systems can be used to design the learning model so that the constraints are automatically satisfied. A few examples of the prior knowledge are kinematic constraints, PDE symmetry, Lagrangian dynamics, and Hamiltonian dynamics. Below are a few interesting papers in this category.</summary></entry><entry><title type="html">Neural ODE Networks (Part 2)</title><link href="http://localhost:4000/my2cents/NeuralODE2/" rel="alternate" type="text/html" title="Neural ODE Networks (Part 2)" /><published>2021-04-01T00:00:00-07:00</published><updated>2021-04-01T00:00:00-07:00</updated><id>http://localhost:4000/my2cents/NeuralODE2</id><content type="html" xml:base="http://localhost:4000/my2cents/NeuralODE2/">&lt;p&gt;&lt;em&gt;Apr. 01, 2021&lt;/em&gt;. I’ll briefly talk about how Neural ODE networks work with Continuous Normalizing Flows (CNF).&lt;/p&gt;
&lt;h2 id=&quot;what-are-continuous-normalizing-flows&quot;&gt;What are Continuous Normalizing Flows?&lt;/h2&gt;
&lt;p&gt;Assume that &lt;script type=&quot;math/tex&quot;&gt;z_0&lt;/script&gt; is a random variable with p.d.f. function &lt;script type=&quot;math/tex&quot;&gt;p(z_0)&lt;/script&gt; and we want to construct a random variable &lt;script type=&quot;math/tex&quot;&gt;z_1&lt;/script&gt; with a desired p.d.f. &lt;script type=&quot;math/tex&quot;&gt;p(z_1)&lt;/script&gt; using a smooth, invertible mapping &lt;script type=&quot;math/tex&quot;&gt;f: \mathbb{R}^n \rightarrow \mathbb{R}&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;z_1 = f(z_0)&lt;/script&gt;. By the change of variable theorem, we have:
\[\log p(z_1) = \log p(z_0) - \log \left|\det \frac{\partial f}{\partial z_0}\right|.\]
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id=&quot;how-do-neural-ode-networks-learn-the-function-f&quot;&gt;How do Neural ODE networks learn the function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;?&lt;/h2&gt;
&lt;p&gt;The main challenge in the CNF problem is the computational complexity of calculating the determinant. Note that this equation is similar to the discrete dynamics we mentioned in &lt;a href=&quot;https://thaipduong.github.io/my2cents/NeuralODE/&quot;&gt;Part 1&lt;/a&gt;. The authors show that when &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; is a finite continous random variable &lt;script type=&quot;math/tex&quot;&gt;z(t)&lt;/script&gt; with p.d.f. &lt;script type=&quot;math/tex&quot;&gt;p(z(t))&lt;/script&gt; and dynamics &lt;script type=&quot;math/tex&quot;&gt;\dot{z} = f(z(t), t)&lt;/script&gt;, the change of variable’s rule turns out to be much simpler:
\[ \frac{\partial p(z(t))}{\partial t} = - \text{tr} \left( \frac{\partial f}{\partial z(t)} \right)\]&lt;/p&gt;

&lt;p&gt;The computational complexity now is significantly reduced because of the trace operation. And given samples from the initial and target distributions, Neural ODE networks can be used to learned the function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; as shown in &lt;a href=&quot;https://thaipduong.github.io/my2cents/NeuralODE/&quot;&gt;Part 1&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Apr. 01, 2021. I’ll briefly talk about how Neural ODE networks work with Continuous Normalizing Flows (CNF). What are Continuous Normalizing Flows? Assume that is a random variable with p.d.f. function and we want to construct a random variable with a desired p.d.f. using a smooth, invertible mapping such that . By the change of variable theorem, we have: \[\log p(z_1) = \log p(z_0) - \log \left|\det \frac{\partial f}{\partial z_0}\right|.\]</summary></entry><entry><title type="html">Neural ODE Networks (Part 1)</title><link href="http://localhost:4000/my2cents/NeuralODE/" rel="alternate" type="text/html" title="Neural ODE Networks (Part 1)" /><published>2021-03-26T00:00:00-07:00</published><updated>2021-03-26T00:00:00-07:00</updated><id>http://localhost:4000/my2cents/NeuralODE</id><content type="html" xml:base="http://localhost:4000/my2cents/NeuralODE/">&lt;p&gt;&lt;em&gt;Mar. 26, 2021&lt;/em&gt;. I’ll summarize an awesome paper: &lt;a href=&quot;https://arxiv.org/abs/1806.07366&quot;&gt;Neural Ordinary Differential Equations&lt;/a&gt; by Ricky Chen et al.&lt;/p&gt;
&lt;h2 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h2&gt;
&lt;p&gt;A dynamical system, e.g. robot dynamics, is often described as:
\[\dot{z} = f(z, t)) \quad\text{(continuous)},\] or
\[z_{t+1} = z_t + f(z_t, t)) \quad \text{(discrete)},\]
where &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is the unknown dynamics function that we want to learn. Let &lt;script type=&quot;math/tex&quot;&gt;\{(z_i, t_i)\}_{i = 0}^N&lt;/script&gt; be a set of &lt;script type=&quot;math/tex&quot;&gt;N + 1&lt;/script&gt; noisy observations of the state &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; at times &lt;script type=&quot;math/tex&quot;&gt;t_0, \ldots, t_N&lt;/script&gt;. &lt;strong&gt;The goal is to approximate the unknown dynamics &lt;script type=&quot;math/tex&quot;&gt;f(z,t)&lt;/script&gt; by &lt;script type=&quot;math/tex&quot;&gt;\hat{f}(z,t,\theta)&lt;/script&gt; and learn the parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; from the noisy observations.&lt;/strong&gt;
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id=&quot;forward-and-backward-passes&quot;&gt;Forward and backward passes&lt;/h2&gt;
&lt;p&gt;Given the parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;, &lt;strong&gt;the forward pass&lt;/strong&gt; predicts the states at times &lt;script type=&quot;math/tex&quot;&gt;t_0, \ldots, t_N&lt;/script&gt; using an ODE solver (e.g. Runge-Kutta methods):
\[ \hat{z}_0, \hat{z}_1, \ldots, \hat{z}_N = \text{ODESolver}(z_0, \hat{f}, t_0, t_1, \ldots, t_N, \theta) \]&lt;/p&gt;

&lt;p&gt;To find the parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;, we typically define a loss function between &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{x}_i&lt;/script&gt; and &lt;strong&gt;back-propagate&lt;/strong&gt; the gradient through the ODE solver. This involves unrolling the steps in the ODE solver and therefore, incurs high memory cost. A key contribution of this paper is to perform back-propagation using &lt;strong&gt;&lt;a href=&quot;https://books.google.com/books/about/Mathematical_Theory_of_Optimal_Processes.html?id=kwzq0F4cBVAC&quot;&gt;adjoint sensitity method&lt;/a&gt;&lt;/strong&gt; that requires only O(1) memory cost.&lt;/p&gt;

&lt;h2 id=&quot;back-propagation&quot;&gt;Back-Propagation&lt;/h2&gt;
&lt;p&gt;For the sake of simplicity, let consider &lt;script type=&quot;math/tex&quot;&gt;N = 1&lt;/script&gt;, i.e. two samples &lt;script type=&quot;math/tex&quot;&gt;z_0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;z_1&lt;/script&gt; at times &lt;script type=&quot;math/tex&quot;&gt;t_0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;t_1&lt;/script&gt;, respectively. Since &lt;script type=&quot;math/tex&quot;&gt;z_0, z_1&lt;/script&gt; are given, the loss function &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is a scalar-valued function of the parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;:
\[ L(z_1) = L(z_0 + \int_{t_0}^{t_1} \hat{f}(z,t,\theta)dt = L(\text{ODESolver}(z_0, \hat{f}, t_0, t_1, \theta)).\]&lt;/p&gt;

&lt;p&gt;Let define the adjoint state as &lt;script type=&quot;math/tex&quot;&gt;a = \frac{\partial L}{\partial z}&lt;/script&gt;. Then, the dynamics of the adjoint state is given by:
\[ \dot{a} = -a^\top \frac{\partial \hat{f}(z,t,\theta)}{\partial z}, \]
and can be solved by an ODE solver backwards in time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://thaipduong.github.io/my2cents/images/posts/neural_ode_net_backprop.png&quot; alt=&quot;&quot; title=&quot;back-propagation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The paper shows that the gradient of the loss &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; w.r.t the parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; depends on both the state &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; and the adjoint state &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;:
\[ \frac{dL}{d\theta} = -\int_{t_0}^{t_1} a^\top \frac{\partial \hat{f}(z,t,\theta)}{\partial \theta}dt.\]
Therefore, we can define an augmented state &lt;script type=&quot;math/tex&quot;&gt;s = [z, a, \frac{dL}{d\theta}]&lt;/script&gt; following the dynamics below:
\[\dot{s} = \begin{bmatrix} \hat{f}(z,t,\theta) \\ -a^\top \frac{\partial \hat{f}(z,t,\theta)}{\partial z} \\ -a^\top \frac{\partial \hat{f}(z,t,\theta)}{\partial \theta} \end{bmatrix},\] with initial state &lt;script type=&quot;math/tex&quot;&gt;s_0 = [z(t_1), a(t_1), 0]&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Solving this reverse-time ODE, requiring only &lt;strong&gt;a single call&lt;/strong&gt; to an ODE solver, returns the gradient &lt;script type=&quot;math/tex&quot;&gt;\frac{dL}{d\theta}&lt;/script&gt; for parameter updates. For &lt;script type=&quot;math/tex&quot;&gt;N &gt; 1&lt;/script&gt;, one single call to the ODE solver is needed for each time interval &lt;script type=&quot;math/tex&quot;&gt;[t_i, t_{i-1}]&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Next time, we will discuss how to propagate a distribution through neural ODE networks.&lt;/p&gt;</content><author><name></name></author><summary type="html">Mar. 26, 2021. I’ll summarize an awesome paper: Neural Ordinary Differential Equations by Ricky Chen et al. Problem Formulation A dynamical system, e.g. robot dynamics, is often described as: \[\dot{z} = f(z, t)) \quad\text{(continuous)},\] or \[z_{t+1} = z_t + f(z_t, t)) \quad \text{(discrete)},\] where is the unknown dynamics function that we want to learn. Let be a set of noisy observations of the state at times . The goal is to approximate the unknown dynamics by and learn the parameters from the noisy observations.</summary></entry><entry><title type="html">Hello World!</title><link href="http://localhost:4000/my2cents/Hello-World/" rel="alternate" type="text/html" title="Hello World!" /><published>2021-03-25T00:00:00-07:00</published><updated>2021-03-25T00:00:00-07:00</updated><id>http://localhost:4000/my2cents/Hello-World</id><content type="html" xml:base="http://localhost:4000/my2cents/Hello-World/">&lt;p&gt;&lt;em&gt;Mar. 25, 2021&lt;/em&gt;. Hello World! Welcome to my blog!&lt;/p&gt;</content><author><name></name></author><summary type="html">Mar. 25, 2021. Hello World! Welcome to my blog!</summary></entry></feed>